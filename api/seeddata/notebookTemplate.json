[{"model": "genie.notebooktemplate", "pk": 1, "fields": {"template": {"paragraphs": [{"text": "%spark.conf\nspark.sql.catalog.lakehouse.warehouse={{warehouseLocation}}", "user": "anonymous", "dateUpdated": "2021-04-16T10:21:11+0000", "progress": 0, "config": {"editorSetting": {"language": "text", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/text", "fontSize": 9, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "runtimeInfos": {}, "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564177042_919230810", "id": "paragraph_1618564177042_919230810", "dateCreated": "2021-04-16T09:09:37+0000", "status": "READY", "focus": true, "$$hashKey": "object:266"}, {"text": "%spark.pyspark\n# ==========================================\n# Oracle connection properties\n# ==========================================\noracleDBHost = \"{{sourceConnection_host}}\"\noracleDBPort = \"{{sourceConnection_port}}\"\noracleDBSID = \"{{sourceConnection_sid}}\"\noracleDBUsername = \"{{sourceConnection_username}}\"\noracleDBPassword = \"{{sourceConnection_password}}\"\noracleDBQuery = \"{{sqlQuery}}\"\nprimaryColumnName = \"{{primaryKeyColumn}}\"\n# ==========================================\n\ndf = spark.read \\\n    .format(\"jdbc\") \\\n    .option(\"url\", f\"jdbc:oracle:thin:@{oracleDBHost}:{oracleDBPort}/{oracleDBSID}\") \\\n    .option(\"query\", oracleDBQuery) \\\n    .option(\"password\", oracleDBPassword) \\\n    .option(\"user\", oracleDBUsername) \\\n    .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\") \\\n    .load()\n    \n# Set order by column for SortOrder\ndf = df.orderBy(\"{{primaryKeyColumn}}\")\n\n# Store results in temp table\ndf.createOrReplaceTempView(\"{{tempTableName}}\")", "user": "anonymous", "dateUpdated": "2021-04-16T10:20:36+0000", "progress": 0, "config": {"tableHide": false, "editorSetting": {"language": "python", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/python", "fontSize": 9, "editorHide": false, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "runtimeInfos": {}, "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169758_666989975", "id": "paragraph_1616145245686_1473486751", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:267"}, {"text": "%spark.sql\nCREATE TABLE IF NOT EXISTS lakehouse.sampledb.{{destinationTableName}} USING iceberg AS SELECT * from {{tempTableName}}", "user": "anonymous", "dateUpdated": "2021-04-16T10:22:19+0000", "progress": 0, "config": {"editorSetting": {"language": "sql", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/sql", "fontSize": 9, "editorHide": false, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "runtimeInfos": {}, "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169763_1116172688", "id": "paragraph_1615528549981_865522288", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:268"}, {"text": "%spark\nval tableName = \"{{destinationTableName}}\"\nimport org.apache.iceberg.aws.glue.GlueCatalog;\nimport scala.collection.JavaConverters.mapAsJavaMapConverter\nimport org.apache.iceberg.actions.Actions;\n\nval properties = Map(\"warehouse\"-> \"{{warehouseLocation}}\").asJava\n\nval catalog = new GlueCatalog();\ncatalog.initialize(\"lakehouse\", properties)\n\n\nimport org.apache.iceberg.Table;\nimport org.apache.iceberg.catalog.TableIdentifier;\n\nval name = TableIdentifier.of(\"sampledb\", tableName);\nval table = catalog.loadTable(name);\n\n// Expire older snapshots and commit\ntable.expireSnapshots().commit()\n\n// Run Compaction for table\nActions.forTable(table).rewriteDataFiles()\n    .targetSizeInBytes(500 * 1024 * 1024 * 10) // 5000 MB\n    .execute();", "user": "anonymous", "dateUpdated": "2021-04-16T10:21:46+0000", "progress": 100, "config": {"editorSetting": {"language": "scala", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/scala", "fontSize": 9, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169763_1339758896", "id": "paragraph_1616655403846_1323321554", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:269"}, {"text": "%spark.pyspark\nmaxVal=spark.sql(f\"SELECT MAX({{timestampColumn}}) FROM lakehouse.sampledb.{{destinationTableName}}\").collect()[0][0]\nprint(maxVal)\nz.put(\"{{tempTableName}}_val\", maxVal)", "user": "anonymous", "dateUpdated": "2021-04-16T10:24:19+0000", "progress": 0, "config": {"editorSetting": {"language": "python", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/python", "fontSize": 9, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169763_75507562", "id": "paragraph_1615885036622_2137552499", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:270"}, {"text": "%spark.sql\n-- SQL Query to configure sort order\nALTER TABLE lakehouse.sampledb.{{destinationTableName}} WRITE ORDERED BY PK;\n\n-- SQL Queyr to configure table properties\n-- ALTER TABLE lakehouse.sampledb.consignmententries  SET TBLPROPERTIES (\n--     'read.split.target-size'='9684354560',\n--     'write.format.default' = 'parquet',\n--     'write.parquet.row-group-size-bytes' = '1342177280',\n--     'write.parquet.page-size-bytes' = '904857600',\n--     'write.target-file-size-bytes' = '134217',\n--     'write.metadata.delete-after-commit.enabled'= 'true',\n--     'write.metadata.previous-versions-max' = 1,\n--     'history.expire.max-snapshot-age-ms' = '4320',\n--     'history.expire.min-snapshots-to-keep' = 1,\n--     'write.spark.fanout.enabled' = 'true',\n--     'write.metadata.metrics.default' = 'none'\n-- )", "user": "anonymous", "dateUpdated": "2021-04-16T10:27:13+0000", "progress": 0, "config": {"editorSetting": {"language": "sql", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/sql", "fontSize": 9, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "runtimeInfos": {}, "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169763_1492999458", "id": "paragraph_1616144051503_913231705", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:271"}, {"text": "%spark.pyspark\nmergeSql = f\"MERGE INTO lakehouse.sampledb.{{destinationTableName}} t USING (SELECT * from {{tempTableName}} where {{timestampColumn}} > \\\"{z.get('{{tempTableName}}_val')}\\\") u ON t.{{primaryKeyColumn}} = u.{{primaryKeyColumn}} WHEN MATCHED THEN UPDATE SET * WHEN NOT MATCHED THEN INSERT *\"\nprint(mergeSql)\nspark.sql(mergeSql)", "user": "anonymous", "dateUpdated": "2021-04-16T10:26:42+0000", "progress": 66, "config": {"editorSetting": {"language": "python", "editOnDblClick": false, "completionKey": "TAB", "completionSupport": true}, "colWidth": 12, "editorMode": "ace/mode/python", "fontSize": 9, "results": {}, "enabled": true}, "settings": {"params": {}, "forms": {}}, "apps": [], "progressUpdateIntervalMs": 500, "jobName": "paragraph_1618564169763_2077416355", "id": "paragraph_1616147422888_2080009648", "dateCreated": "2021-04-16T09:09:29+0000", "status": "READY", "$$hashKey": "object:272"}], "name": "{{name}}", "defaultInterpreterGroup": "spark", "version": "0.9.0", "noteParams": {}, "noteForms": {}, "angularObjects": {}, "config": {"isZeppelinNotebookCronEnable": false, "looknfeel": "default", "personalizedMode": "false"}, "info": {"isRunning": false}}, "formJson": {"fields": [{"name": "sourceConnection", "label": "Source Connection", "rules": [{"required": true, "message": "Source Connection is required"}], "type": "connectionSelect", "filter": ["Oracle"]}, {"name": "sqlQuery", "label": "SQL Query", "rules": [{"required": true, "message": "SQL Query is required"}], "type": "sql"}, {"name": "timestampColumn", "label": "Timestamp Column", "rules": [{"required": true, "message": "Timestamp Column is required"}], "type": "text"}, {"name": "primaryKeyColumn", "label": "Primary Key Column", "rules": [{"required": true, "message": "Primary Key Column is required"}], "type": "text"}, {"name": "destinationTableS3Path", "label": "Destination Table S3 Path", "rules": [{"required": true, "message": "Destination Table S3 Path is required"}], "type": "text"}]}, "name": "Incremental Refresh"}}]